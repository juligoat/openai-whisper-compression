{
    "model.encoder.conv1.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "other",
            "layer_num": -1,
            "attention_type": "none"
        },
        "shape": [768, 80, 3],
        "size": 184320,
        "param_sample": [
            -0.0064544677734375, -0.0064544677734375, -0.0148773193359375,
            0.0282745361328125, 0.0298919677734375
        ],
        "importance": 0.027827780152889756,
        "fisher": 0.00011413820726981309,
        "snip": 0.00012577461263087267,
        "gradient_count": 30,
        "importance_raw": 0.00011995640995034288
    },
    "model.encoder.conv2.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "other",
            "layer_num": -1,
            "attention_type": "none"
        },
        "shape": [768, 768, 3],
        "size": 1769472,
        "param_sample": [
            -0.005725860595703125, -0.00823974609375, -0.01441192626953125,
            -0.0005507469177246094, -0.007648468017578125
        ],
        "importance": 0.00225102327046639,
        "fisher": 1.0145040171967896e-5,
        "snip": 1.803147918811495e-5,
        "gradient_count": 30,
        "importance_raw": 1.4088259680041423e-5
    },
    "model.encoder.layers.0.self_attn.k_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 0,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.006481170654296875, 0.00998687744140625, 0.00444793701171875,
            0.0039825439453125, 0.002223968505859375
        ],
        "importance": 0.0,
        "fisher": 3.4338339257071008e-6,
        "snip": 6.107666854404669e-6,
        "gradient_count": 30,
        "importance_raw": 4.7707503900558855e-6
    },
    "model.encoder.layers.0.self_attn.v_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 0,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.00687408447265625, 0.025115966796875, -0.0039520263671875,
            0.0328369140625, 0.0185546875
        ],
        "importance": 0.10839418527649315,
        "fisher": 0.0008395639272445502,
        "snip": 6.731510135675005e-5,
        "gradient_count": 30,
        "importance_raw": 0.0004534395143006501
    },
    "model.encoder.layers.0.self_attn.q_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 0,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.0034770965576171875, 0.0084686279296875, 0.01080322265625,
            0.00946044921875, 0.0008835792541503906
        ],
        "importance": 0.00017219399125897425,
        "fisher": 5.4326445592778326e-6,
        "snip": 5.534358244100682e-6,
        "gradient_count": 30,
        "importance_raw": 5.483501401689257e-6
    },
    "model.encoder.layers.0.self_attn.out_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 0,
            "attention_type": "output_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.0019273757934570312, 0.0221710205078125, 0.0165557861328125,
            0.0230865478515625, 0.0036373138427734375
        ],
        "importance": 0.05949337746738149,
        "fisher": 0.00038692480860239205,
        "snip": 0.00011513056754968905,
        "gradient_count": 30,
        "importance_raw": 0.00025102768807604056
    },
    "model.encoder.layers.0.fc1.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "feed_forward",
            "layer_num": 0,
            "attention_type": "none"
        },
        "shape": [3072, 768],
        "size": 2359296,
        "param_sample": [
            0.017608642578125, 0.000324249267578125, -0.004955291748046875,
            0.00453948974609375, -0.01885986328125
        ],
        "importance": 0.0033394034660947695,
        "fisher": 2.2002668917290672e-5,
        "snip": 1.5183968389465009e-5,
        "gradient_count": 30,
        "importance_raw": 1.859331865337784e-5
    },
    "model.encoder.layers.0.fc2.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "feed_forward",
            "layer_num": 0,
            "attention_type": "none"
        },
        "shape": [768, 3072],
        "size": 2359296,
        "param_sample": [
            0.00894927978515625, 0.0110015869140625, 0.01480865478515625,
            0.00533294677734375, -9.40561294555664e-5
        ],
        "importance": 0.00511985764138125,
        "fisher": 3.319286089814947e-5,
        "snip": 1.8733204948754672e-5,
        "gradient_count": 30,
        "importance_raw": 2.5963032923452073e-5
    },
    "model.encoder.layers.1.self_attn.k_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 1,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.0186614990234375, 0.00872802734375, 0.0023593902587890625,
            -0.01139068603515625, 0.00244903564453125
        ],
        "importance": 0.0002809434085790819,
        "fisher": 1.567195417351286e-6,
        "snip": 1.030008569008108e-5,
        "gradient_count": 30,
        "importance_raw": 5.933640553716183e-6
    },
    "model.encoder.layers.1.self_attn.v_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 1,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.0167236328125, 0.026123046875, -0.00855255126953125,
            -0.08697509765625, 0.00019550323486328125
        ],
        "importance": 0.0070050364943276475,
        "fisher": 3.816659277617873e-5,
        "snip": 2.9365861246333223e-5,
        "gradient_count": 30,
        "importance_raw": 3.376622701125597e-5
    },
    "model.encoder.layers.1.self_attn.q_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 1,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.0105743408203125, -0.003223419189453125, -0.007114410400390625,
            0.003910064697265625, -0.0010223388671875
        ],
        "importance": 0.00027340125582240785,
        "fisher": 1.5911402869051016e-6,
        "snip": 1.0213703368814701e-5,
        "gradient_count": 30,
        "importance_raw": 5.902421827859901e-6
    },
    "model.encoder.layers.1.self_attn.out_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 1,
            "attention_type": "output_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.00308990478515625, 0.08233642578125, 0.25732421875, 0.0927734375,
            0.20166015625
        ],
        "importance": 0.007862342873308793,
        "fisher": 3.707020444683925e-5,
        "snip": 3.755943089345237e-5,
        "gradient_count": 30,
        "importance_raw": 3.7314817670145814e-5
    },
    "model.encoder.layers.1.fc1.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "feed_forward",
            "layer_num": 1,
            "attention_type": "none"
        },
        "shape": [3072, 768],
        "size": 2359296,
        "param_sample": [
            -0.0025806427001953125, -0.003204345703125, -0.04876708984375,
            -0.00177764892578125, 0.00553131103515625
        ],
        "importance": 0.001480716150226783,
        "fisher": 9.512766018815455e-6,
        "snip": 1.2286792389204492e-5,
        "gradient_count": 30,
        "importance_raw": 1.0899779204009974e-5
    },
    "model.encoder.layers.1.fc2.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "feed_forward",
            "layer_num": 1,
            "attention_type": "none"
        },
        "shape": [768, 3072],
        "size": 2359296,
        "param_sample": [
            7.170438766479492e-5, 0.01361083984375, 0.0001442432403564453,
            -0.016021728515625, -0.011505126953125
        ],
        "importance": 0.0016824286426421252,
        "fisher": 8.794482702493649e-6,
        "snip": 1.4674945623482926e-5,
        "gradient_count": 30,
        "importance_raw": 1.1734714162988288e-5
    },
    "model.encoder.layers.2.self_attn.k_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 2,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.01039886474609375, 0.0119781494140625, 0.0147552490234375,
            0.01355743408203125, -0.0020160675048828125
        ],
        "importance": 0.0002096744572711986,
        "fisher": 1.8815200377275687e-6,
        "snip": 9.39576351205081e-6,
        "gradient_count": 30,
        "importance_raw": 5.63864177488919e-6
    },
    "model.encoder.layers.2.self_attn.v_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 2,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.0150604248046875, 0.0024871826171875, 0.0175933837890625,
            -0.0114593505859375, 0.001987457275390625
        ],
        "importance": 0.007785144278788082,
        "fisher": 4.3152118072005884e-5,
        "snip": 3.08384313636149e-5,
        "gradient_count": 30,
        "importance_raw": 3.699527471781039e-5
    },
    "model.encoder.layers.2.self_attn.q_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 2,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.012908935546875, -0.0106964111328125, -0.00787353515625,
            -0.01192474365234375, -0.0008854866027832031
        ],
        "importance": 0.00012699824601704947,
        "fisher": 1.7716303479649772e-6,
        "snip": 8.821221035759663e-6,
        "gradient_count": 30,
        "importance_raw": 5.29642569186232e-6
    },
    "model.encoder.layers.2.self_attn.out_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 2,
            "attention_type": "output_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.008392333984375, 0.004436492919921875, -0.005168914794921875,
            0.01398468017578125, 0.00963592529296875
        ],
        "importance": 0.0080241405448469,
        "fisher": 3.561596330049118e-5,
        "snip": 4.035310848848894e-5,
        "gradient_count": 30,
        "importance_raw": 3.798453589449006e-5
    },
    "model.encoder.layers.2.fc1.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "feed_forward",
            "layer_num": 2,
            "attention_type": "none"
        },
        "shape": [3072, 768],
        "size": 2359296,
        "param_sample": [
            0.00577545166015625, -0.006885528564453125, 0.0025272369384765625,
            0.00505828857421875, 0.0110626220703125
        ],
        "importance": 0.0014933078181325323,
        "fisher": 7.793538922366375e-6,
        "snip": 1.4110259174534197e-5,
        "gradient_count": 30,
        "importance_raw": 1.0951899048450286e-5
    },
    "model.encoder.layers.2.fc2.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "feed_forward",
            "layer_num": 2,
            "attention_type": "none"
        },
        "shape": [768, 3072],
        "size": 2359296,
        "param_sample": [
            0.01280975341796875, 0.002933502197265625, 0.004291534423828125,
            0.01068878173828125, 0.0006880760192871094
        ],
        "importance": 0.0016761204541691707,
        "fisher": 7.4442382621479435e-6,
        "snip": 1.5972967942919544e-5,
        "gradient_count": 30,
        "importance_raw": 1.1708603102533745e-5
    },
    "model.encoder.layers.3.self_attn.k_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 3,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.0279998779296875, -0.01091766357421875, 0.029449462890625,
            -0.01220703125, -0.0030059814453125
        ],
        "importance": 0.0007719709131266824,
        "fisher": 3.2902669573786627e-6,
        "snip": 1.2641968426881552e-5,
        "gradient_count": 30,
        "importance_raw": 7.966117692130108e-6
    },
    "model.encoder.layers.3.self_attn.v_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 3,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.006206512451171875, 0.0028839111328125, 0.0128936767578125,
            0.0129852294921875, -0.00543975830078125
        ],
        "importance": 0.008007183871967324,
        "fisher": 4.258545163793315e-5,
        "snip": 3.3243244918897595e-5,
        "gradient_count": 30,
        "importance_raw": 3.7914348278415374e-5
    },
    "model.encoder.layers.3.self_attn.q_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 3,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.0115814208984375, -0.0018453598022460938, 0.01556396484375,
            0.0009045600891113281, -0.004009246826171875
        ],
        "importance": 0.00044297297513199737,
        "fisher": 2.3480660928498763e-6,
        "snip": 1.0860571198160566e-5,
        "gradient_count": 30,
        "importance_raw": 6.6043186455052215e-6
    },
    "model.encoder.layers.3.self_attn.out_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 3,
            "attention_type": "output_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.01045989990234375, -0.01308441162109375, 0.01898193359375,
            -0.00045013427734375, -0.010498046875
        ],
        "importance": 0.00681815451722948,
        "fisher": 2.68323589504386e-5,
        "snip": 3.9152999064147784e-5,
        "gradient_count": 30,
        "importance_raw": 3.2992679007293194e-5
    },
    "model.encoder.layers.3.fc1.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "feed_forward",
            "layer_num": 3,
            "attention_type": "none"
        },
        "shape": [3072, 768],
        "size": 2359296,
        "param_sample": [
            -0.00917816162109375, -0.01352691650390625, -0.0240936279296875,
            -0.020172119140625, 0.00255584716796875
        ],
        "importance": 0.0017934850335866407,
        "fisher": 8.672539494606706e-6,
        "snip": 1.571626533708089e-5,
        "gradient_count": 30,
        "importance_raw": 1.2194402415843797e-5
    },
    "model.encoder.layers.3.fc2.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "feed_forward",
            "layer_num": 3,
            "attention_type": "none"
        },
        "shape": [768, 3072],
        "size": 2359296,
        "param_sample": [
            -0.0029354095458984375, -0.00201416015625, 0.024688720703125,
            0.023162841796875, -0.0239410400390625
        ],
        "importance": 0.001930132481020072,
        "fisher": 7.674525363654539e-6,
        "snip": 1.7845510653084298e-5,
        "gradient_count": 30,
        "importance_raw": 1.2760018008369418e-5
    },
    "model.encoder.layers.4.self_attn.k_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 4,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.0018215179443359375, 0.009307861328125, 0.00971221923828125,
            0.0040740966796875, 0.0125579833984375
        ],
        "importance": 0.0009439188445192156,
        "fisher": 3.1044987811886434e-6,
        "snip": 1.4251201628212585e-5,
        "gradient_count": 30,
        "importance_raw": 8.677850204700615e-6
    },
    "model.encoder.layers.4.self_attn.v_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 4,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.032623291015625, -0.01465606689453125, -0.0022678375244140625,
            -0.0158843994140625, -0.0046539306640625
        ],
        "importance": 0.007050533393069975,
        "fisher": 3.201897513160172e-5,
        "snip": 3.58901233994402e-5,
        "gradient_count": 30,
        "importance_raw": 3.395454926552096e-5
    },
    "model.encoder.layers.4.self_attn.q_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 4,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.00048542022705078125, 0.0011501312255859375, -0.0308074951171875,
            -0.0054473876953125, 0.0295257568359375
        ],
        "importance": 0.0008314683208963247,
        "fisher": 2.7838691759522288e-6,
        "snip": 1.364091344839835e-5,
        "gradient_count": 30,
        "importance_raw": 8.212391312175289e-6
    },
    "model.encoder.layers.4.self_attn.out_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 4,
            "attention_type": "output_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.0297393798828125, -0.002471923828125, -0.0015840530395507812,
            0.004344940185546875, -0.0035724639892578125
        ],
        "importance": 0.007616268326462191,
        "fisher": 3.2363579111915894e-5,
        "snip": 4.0228936571414425e-5,
        "gradient_count": 30,
        "importance_raw": 3.629625784166516e-5
    },
    "model.encoder.layers.4.fc1.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "feed_forward",
            "layer_num": 4,
            "attention_type": "none"
        },
        "shape": [3072, 768],
        "size": 2359296,
        "param_sample": [
            0.00463104248046875, -0.007354736328125, -0.0086212158203125,
            -0.032745361328125, 0.0136871337890625
        ],
        "importance": 0.002598287432316796,
        "fisher": 1.1648076080443085e-5,
        "snip": 1.9403257677671112e-5,
        "gradient_count": 30,
        "importance_raw": 1.5525666879057098e-5
    },
    "model.encoder.layers.4.fc2.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "feed_forward",
            "layer_num": 4,
            "attention_type": "none"
        },
        "shape": [768, 3072],
        "size": 2359296,
        "param_sample": [
            0.028900146484375, 0.01496124267578125, 0.0033435821533203125,
            -0.002471923828125, -0.030059814453125
        ],
        "importance": 0.002501303740159759,
        "fisher": 9.051168967744161e-6,
        "snip": 2.1197288636661444e-5,
        "gradient_count": 30,
        "importance_raw": 1.5124228802202803e-5
    },
    "model.encoder.layers.5.self_attn.k_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 5,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.01641845703125, -0.015869140625, -0.043365478515625,
            -0.004505157470703125, -0.0007371902465820312
        ],
        "importance": 0.0010921326363147782,
        "fisher": 4.024308884709171e-6,
        "snip": 1.4558374292998148e-5,
        "gradient_count": 30,
        "importance_raw": 9.291341588853658e-6
    },
    "model.encoder.layers.5.self_attn.v_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 5,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.01322174072265625, -0.010498046875, -0.01439666748046875,
            0.00780487060546875, -0.013763427734375
        ],
        "importance": 0.009658065234081534,
        "fisher": 4.8996691020875005e-5,
        "snip": 4.049877000700993e-5,
        "gradient_count": 30,
        "importance_raw": 4.4747730513942466e-5
    },
    "model.encoder.layers.5.self_attn.q_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 5,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.0005178451538085938, -0.00864410400390625, 0.0009398460388183594,
            -0.0277557373046875, -0.0130462646484375
        ],
        "importance": 0.0008538219640666768,
        "fisher": 3.747138760938166e-6,
        "snip": 1.2862697728148002e-5,
        "gradient_count": 30,
        "importance_raw": 8.304918244543084e-6
    },
    "model.encoder.layers.5.self_attn.out_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 5,
            "attention_type": "output_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.0014028549194335938, 0.0099334716796875, 0.00595855712890625,
            -0.005779266357421875, -0.0355224609375
        ],
        "importance": 0.008405277962636175,
        "fisher": 3.350719956263977e-5,
        "snip": 4.561710520647466e-5,
        "gradient_count": 30,
        "importance_raw": 3.9562152384557214e-5
    },
    "model.encoder.layers.5.fc1.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "feed_forward",
            "layer_num": 5,
            "attention_type": "none"
        },
        "shape": [3072, 768],
        "size": 2359296,
        "param_sample": [
            0.00145721435546875, -0.012969970703125, -0.06488037109375,
            -0.0247039794921875, 0.0158233642578125
        ],
        "importance": 0.0032057751229775462,
        "fisher": 1.3574576867843764e-5,
        "snip": 2.2505822804911683e-5,
        "gradient_count": 30,
        "importance_raw": 1.8040199836377725e-5
    },
    "model.encoder.layers.5.fc2.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "feed_forward",
            "layer_num": 5,
            "attention_type": "none"
        },
        "shape": [768, 3072],
        "size": 2359296,
        "param_sample": [
            0.006717681884765625, 0.034027099609375, 0.037384033203125,
            -0.028594970703125, -0.001041412353515625
        ],
        "importance": 0.0030756945417307856,
        "fisher": 1.0803445654043269e-5,
        "snip": 2.4200086409109643e-5,
        "gradient_count": 30,
        "importance_raw": 1.7501766031576456e-5
    },
    "model.encoder.layers.6.self_attn.k_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 6,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.0119781494140625, -0.0171966552734375, -0.0034618377685546875,
            -0.0017986297607421875, 0.007053375244140625
        ],
        "importance": 0.0020488694183257747,
        "fisher": 6.27522904323996e-6,
        "snip": 2.0227766617608724e-5,
        "gradient_count": 30,
        "importance_raw": 1.3251497830424342e-5
    },
    "model.encoder.layers.6.self_attn.v_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 6,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.0007615089416503906, -0.004947662353515625, -0.01149749755859375,
            -0.0227203369140625, -0.0022487640380859375
        ],
        "importance": 0.006928478494650611,
        "fisher": 2.8367880804580637e-5,
        "snip": 3.853079045560056e-5,
        "gradient_count": 30,
        "importance_raw": 3.34493356300906e-5
    },
    "model.encoder.layers.6.self_attn.q_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 6,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.0266571044921875, -0.007171630859375, -0.00418853759765625,
            0.0106964111328125, -0.01160430908203125
        ],
        "importance": 0.0016377583363202212,
        "fisher": 4.573784243196617e-6,
        "snip": 1.852584249112018e-5,
        "gradient_count": 30,
        "importance_raw": 1.1549813367158398e-5
    },
    "model.encoder.layers.6.self_attn.out_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 6,
            "attention_type": "output_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.00749969482421875, -0.03192138671875, -0.0721435546875,
            -0.00400543212890625, -0.003360748291015625
        ],
        "importance": 0.007154120348931213,
        "fisher": 2.5455376953686936e-5,
        "snip": 4.3311262622106976e-5,
        "gradient_count": 30,
        "importance_raw": 3.4383319787896954e-5
    },
    "model.encoder.layers.6.fc1.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "feed_forward",
            "layer_num": 6,
            "attention_type": "none"
        },
        "shape": [3072, 768],
        "size": 2359296,
        "param_sample": [
            0.006153106689453125, -0.02783203125, -0.0210723876953125,
            -0.008331298828125, 0.0178070068359375
        ],
        "importance": 0.003450904566661848,
        "fisher": 1.382097932491888e-5,
        "snip": 2.4288716000834636e-5,
        "gradient_count": 30,
        "importance_raw": 1.9054847662876757e-5
    },
    "model.encoder.layers.6.fc2.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "feed_forward",
            "layer_num": 6,
            "attention_type": "none"
        },
        "shape": [768, 3072],
        "size": 2359296,
        "param_sample": [
            0.0083160400390625, -0.0059051513671875, 0.0133514404296875,
            -0.01052093505859375, -0.032562255859375
        ],
        "importance": 0.010534515416396042,
        "fisher": 6.862693984051778e-5,
        "snip": 2.8124183821394884e-5,
        "gradient_count": 30,
        "importance_raw": 4.8375561830956335e-5
    },
    "model.encoder.layers.7.self_attn.k_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 7,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.01549530029296875, 0.01300048828125, 0.0026683807373046875,
            0.01105499267578125, 0.01873779296875
        ],
        "importance": 0.001880412984559626,
        "fisher": 5.599505285166136e-6,
        "snip": 1.9508929593333354e-5,
        "gradient_count": 30,
        "importance_raw": 1.2554217439249745e-5
    },
    "model.encoder.layers.7.self_attn.v_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 7,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.01291656494140625, -0.0092926025390625, 0.00469970703125,
            -0.0244598388671875, -0.059722900390625
        ],
        "importance": 0.015841968646768432,
        "fisher": 8.29784259015772e-5,
        "snip": 5.771026644652011e-5,
        "gradient_count": 30,
        "importance_raw": 7.034434617404864e-5
    },
    "model.encoder.layers.7.self_attn.q_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 7,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.018310546875, -0.0189056396484375, 0.003543853759765625,
            0.0189208984375, 0.0198516845703125
        ],
        "importance": 0.0014317688714669417,
        "fisher": 4.088103177461259e-6,
        "snip": 1.7306246869945124e-5,
        "gradient_count": 30,
        "importance_raw": 1.0697175023703192e-5
    },
    "model.encoder.layers.7.self_attn.out_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 7,
            "attention_type": "output_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.0113677978515625, -0.00024116039276123047, -0.00592803955078125,
            -0.011627197265625, 0.034515380859375
        ],
        "importance": 0.01589387006756325,
        "fisher": 7.515753031839267e-5,
        "snip": 6.596082615336248e-5,
        "gradient_count": 30,
        "importance_raw": 7.055917823587757e-5
    },
    "model.encoder.layers.7.fc1.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "feed_forward",
            "layer_num": 7,
            "attention_type": "none"
        },
        "shape": [3072, 768],
        "size": 2359296,
        "param_sample": [
            0.00506591796875, -0.007564544677734375, -0.007061004638671875,
            0.00553131103515625, -0.00809478759765625
        ],
        "importance": 0.003973873229026029,
        "fisher": 1.5697058385436926e-5,
        "snip": 2.6742014991517257e-5,
        "gradient_count": 30,
        "importance_raw": 2.121953668847709e-5
    },
    "model.encoder.layers.7.fc2.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "feed_forward",
            "layer_num": 7,
            "attention_type": "none"
        },
        "shape": [768, 3072],
        "size": 2359296,
        "param_sample": [
            -0.0066070556640625, 0.034515380859375, -0.01422119140625,
            -0.0010099411010742188, -0.0103607177734375
        ],
        "importance": 0.0037197619224437757,
        "fisher": 1.1899172432094928e-5,
        "snip": 2.843624924935284e-5,
        "gradient_count": 30,
        "importance_raw": 2.0167710840723884e-5
    },
    "model.encoder.layers.8.self_attn.k_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 8,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.02783203125, 0.01690673828125, 0.04736328125, 0.047882080078125,
            -0.01218414306640625
        ],
        "importance": 0.0029779405393645353,
        "fisher": 8.952249766025489e-6,
        "snip": 2.524202915689481e-5,
        "gradient_count": 30,
        "importance_raw": 1.709713946146015e-5
    },
    "model.encoder.layers.8.self_attn.v_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 8,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.0018358230590820312, -0.01251983642578125, 0.01678466796875,
            -0.011199951171875, 0.005397796630859375
        ],
        "importance": 0.011501209143713447,
        "fisher": 5.48015047267351e-5,
        "snip": 4.995235964694681e-5,
        "gradient_count": 30,
        "importance_raw": 5.237693218684096e-5
    },
    "model.encoder.layers.8.self_attn.q_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 8,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.0051422119140625, 0.0002837181091308594, 0.0012836456298828125,
            0.03094482421875, 0.037353515625
        ],
        "importance": 0.0025869118641017605,
        "fisher": 7.482105206690903e-6,
        "snip": 2.3475056301928514e-5,
        "gradient_count": 30,
        "importance_raw": 1.5478580754309707e-5
    },
    "model.encoder.layers.8.self_attn.out_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 8,
            "attention_type": "output_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.005802154541015625, 0.02142333984375, 0.016082763671875,
            -0.01702880859375, 0.005550384521484375
        ],
        "importance": 0.011282770506100298,
        "fisher": 4.647709677859287e-5,
        "snip": 5.646843086045313e-5,
        "gradient_count": 30,
        "importance_raw": 5.1472763819523e-5
    },
    "model.encoder.layers.8.fc1.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "feed_forward",
            "layer_num": 8,
            "attention_type": "none"
        },
        "shape": [3072, 768],
        "size": 2359296,
        "param_sample": [
            0.013336181640625, 0.0246734619140625, 0.0033721923828125,
            0.01525115966796875, 0.0316162109375
        ],
        "importance": 0.0031611796038679358,
        "fisher": 1.6563964550186938e-5,
        "snip": 1.9147252654268717e-5,
        "gradient_count": 30,
        "importance_raw": 1.785560860222783e-5
    },
    "model.encoder.layers.8.fc2.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "feed_forward",
            "layer_num": 8,
            "attention_type": "none"
        },
        "shape": [768, 3072],
        "size": 2359296,
        "param_sample": [
            0.01496124267578125, -0.0177764892578125, -0.006626129150390625,
            -0.0298309326171875, -0.01171875
        ],
        "importance": 0.0023885216714618065,
        "fisher": 1.3619267080381785e-5,
        "snip": 1.569552805449348e-5,
        "gradient_count": 30,
        "importance_raw": 1.4657397567437632e-5
    },
    "model.encoder.layers.9.self_attn.k_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 9,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.00457000732421875, -0.01514434814453125, -0.05303955078125,
            0.0264129638671875, -0.01361083984375
        ],
        "importance": 0.0027842815566290536,
        "fisher": 8.315966836865603e-6,
        "snip": 2.4275112870479158e-5,
        "gradient_count": 30,
        "importance_raw": 1.629553985367238e-5
    },
    "model.encoder.layers.9.self_attn.v_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 9,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.027313232421875, 0.028656005859375, 0.0152740478515625,
            -0.01153564453125, 0.01561737060546875
        ],
        "importance": 0.01482870659739652,
        "fisher": 7.22684696787231e-5,
        "snip": 6.003196770810367e-5,
        "gradient_count": 30,
        "importance_raw": 6.615021869341338e-5
    },
    "model.encoder.layers.9.self_attn.q_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 9,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.039520263671875, 0.01042938232421875, -0.005672454833984375,
            0.04168701171875, 0.01326751708984375
        ],
        "importance": 0.0027277410883882153,
        "fisher": 8.035325367927727e-6,
        "snip": 2.4087686021327197e-5,
        "gradient_count": 30,
        "importance_raw": 1.6061505694627463e-5
    },
    "model.encoder.layers.9.self_attn.out_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 9,
            "attention_type": "output_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.00986480712890625, 0.004497528076171875, -0.00832366943359375,
            -0.004367828369140625, -0.0006422996520996094
        ],
        "importance": 0.016501531068488198,
        "fisher": 7.060699505624749e-5,
        "snip": 7.55418620731992e-5,
        "gradient_count": 30,
        "importance_raw": 7.307442856472335e-5
    },
    "model.encoder.layers.9.fc1.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "feed_forward",
            "layer_num": 9,
            "attention_type": "none"
        },
        "shape": [3072, 768],
        "size": 2359296,
        "param_sample": [
            -0.01641845703125, -0.01342010498046875, 0.017669677734375,
            0.00347900390625, 0.0023555755615234375
        ],
        "importance": 0.0026872802653805715,
        "fisher": 1.6990573969148196e-5,
        "snip": 1.4797483891015872e-5,
        "gradient_count": 30,
        "importance_raw": 1.5894028930082035e-5
    },
    "model.encoder.layers.9.fc2.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "feed_forward",
            "layer_num": 9,
            "attention_type": "none"
        },
        "shape": [768, 3072],
        "size": 2359296,
        "param_sample": [
            -0.015777587890625, 0.0206298828125, -0.0149993896484375,
            0.0186767578125, -0.01062774658203125
        ],
        "importance": 0.002825612536285766,
        "fisher": 1.9580214726981163e-5,
        "snip": 1.3353022071290373e-5,
        "gradient_count": 30,
        "importance_raw": 1.6466618399135767e-5
    },
    "model.encoder.layers.10.self_attn.k_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 10,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.032745361328125, -0.004398345947265625, -0.004802703857421875,
            0.0195770263671875, 0.0013990402221679688
        ],
        "importance": 0.00614144615114448,
        "fisher": 2.6161956823974228e-5,
        "snip": 3.422129429964116e-5,
        "gradient_count": 30,
        "importance_raw": 3.0191625561807693e-5
    },
    "model.encoder.layers.10.self_attn.v_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 10,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.0120391845703125, 0.004261016845703125, -0.005390167236328125,
            -0.0263214111328125, -0.06256103515625
        ],
        "importance": 0.017692447170706158,
        "fisher": 9.175178214112141e-5,
        "snip": 6.425603290457123e-5,
        "gradient_count": 30,
        "importance_raw": 7.800390752284632e-5
    },
    "model.encoder.layers.10.self_attn.q_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 10,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.01142120361328125, -0.0077972412109375, -0.01268768310546875,
            0.0179901123046875, -0.0140228271484375
        ],
        "importance": 0.005743328787890469,
        "fisher": 2.3017790120623734e-5,
        "snip": 3.406966012941363e-5,
        "gradient_count": 30,
        "importance_raw": 2.8543725125018683e-5
    },
    "model.encoder.layers.10.self_attn.out_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 10,
            "attention_type": "output_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.0374755859375, -0.007373809814453125, 0.0101165771484375,
            0.0207672119140625, -0.002758026123046875
        ],
        "importance": 0.017245364154610962,
        "fisher": 7.122568040358601e-5,
        "snip": 8.108097329871574e-5,
        "gradient_count": 30,
        "importance_raw": 7.615332685115088e-5
    },
    "model.encoder.layers.10.fc1.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "feed_forward",
            "layer_num": 10,
            "attention_type": "none"
        },
        "shape": [3072, 768],
        "size": 2359296,
        "param_sample": [
            0.040130615234375, -0.0259857177734375, 0.01561737060546875,
            0.00952911376953125, -0.01611328125
        ],
        "importance": 0.004460478146575345,
        "fisher": 2.6387739580968628e-5,
        "snip": 2.00796758387393e-5,
        "gradient_count": 30,
        "importance_raw": 2.3233707709853962e-5
    },
    "model.encoder.layers.10.fc2.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "feed_forward",
            "layer_num": 10,
            "attention_type": "none"
        },
        "shape": [768, 3072],
        "size": 2359296,
        "param_sample": [
            -0.08636474609375, 0.01024627685546875, 0.0007987022399902344,
            0.023193359375, 0.01454925537109375
        ],
        "importance": 0.003611062323859577,
        "fisher": 2.2968596764864437e-5,
        "snip": 1.6466959035218073e-5,
        "gradient_count": 30,
        "importance_raw": 1.9717777900041255e-5
    },
    "model.encoder.layers.11.self_attn.k_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 11,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.0117340087890625, 0.00013899803161621094, 0.0136566162109375,
            -0.00466156005859375, 0.00774383544921875
        ],
        "importance": 0.008373943241285202,
        "fisher": 3.757210191300449e-5,
        "snip": 4.1292799445121393e-5,
        "gradient_count": 30,
        "importance_raw": 3.943245067906294e-5
    },
    "model.encoder.layers.11.self_attn.v_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 11,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.0238800048828125, -0.0233917236328125, -0.0116729736328125,
            -0.00634002685546875, 0.01849365234375
        ],
        "importance": 0.025678166607834733,
        "fisher": 0.00012866301998049797,
        "snip": 9.345429825771134e-5,
        "gradient_count": 30,
        "importance_raw": 0.00011105865911910465
    },
    "model.encoder.layers.11.self_attn.q_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 11,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.006618499755859375, 0.0015468597412109375, 0.035308837890625,
            0.00997161865234375, 0.0005750656127929688
        ],
        "importance": 0.007137023229387636,
        "fisher": 2.898663487940212e-5,
        "snip": 3.963846678137391e-5,
        "gradient_count": 30,
        "importance_raw": 3.4312550830388015e-5
    },
    "model.encoder.layers.11.self_attn.out_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "self_attention",
            "layer_num": 11,
            "attention_type": "output_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.024139404296875, 0.00644683837890625, 0.0034503936767578125,
            -0.0093994140625, 0.0194244384765625
        ],
        "importance": 0.024103518256837785,
        "fisher": 0.00010383308993671866,
        "snip": 0.00010524855618617342,
        "gradient_count": 30,
        "importance_raw": 0.00010454082306144604
    },
    "model.encoder.layers.11.fc1.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "feed_forward",
            "layer_num": 11,
            "attention_type": "none"
        },
        "shape": [3072, 768],
        "size": 2359296,
        "param_sample": [
            0.0021533966064453125, -0.0293426513671875, -0.004970550537109375,
            -0.00794219970703125, 0.007904052734375
        ],
        "importance": 0.00885644122504067,
        "fisher": 4.944242449103816e-5,
        "snip": 3.341681979994367e-5,
        "gradient_count": 30,
        "importance_raw": 4.142962214549091e-5
    },
    "model.encoder.layers.11.fc2.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "feed_forward",
            "layer_num": 11,
            "attention_type": "none"
        },
        "shape": [768, 3072],
        "size": 2359296,
        "param_sample": [
            -0.014129638671875, -0.007476806640625, -0.035003662109375,
            0.02923583984375, 0.0145263671875
        ],
        "importance": 0.00819886898471629,
        "fisher": 4.7704176601352326e-5,
        "snip": 2.971137855638517e-5,
        "gradient_count": 30,
        "importance_raw": 3.8707777578868746e-5
    },
    "model.decoder.embed_tokens.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "embedding",
            "layer_num": -1,
            "attention_type": "none"
        },
        "shape": [51865, 768],
        "size": 39832320,
        "param_sample": [
            0.005481719970703125, -0.005664825439453125, 0.01326751708984375,
            0.013153076171875, 0.01873779296875
        ],
        "importance": 0.01745327148693171,
        "fisher": 0.00015131405167873407,
        "snip": 2.7137557102226615e-6,
        "gradient_count": 30,
        "importance_raw": 7.701390369447837e-5
    },
    "model.decoder.embed_positions.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "embedding",
            "layer_num": -1,
            "attention_type": "none"
        },
        "shape": [448, 768],
        "size": 344064,
        "param_sample": [
            0.004253387451171875, 0.0009598731994628906, 0.01082611083984375,
            -0.004425048828125, -0.00154876708984375
        ],
        "importance": 1.0,
        "fisher": 0.008210744592361152,
        "snip": 7.7262450940907e-5,
        "gradient_count": 30,
        "importance_raw": 0.00414400352165103
    },
    "model.decoder.layers.0.self_attn.k_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 0,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.01357269287109375, 0.04656982421875, 0.009857177734375,
            -0.01352691650390625, 0.0023651123046875
        ],
        "importance": 0.0052811628468900414,
        "fisher": 1.600606105209105e-5,
        "snip": 3.725536438044704e-5,
        "gradient_count": 30,
        "importance_raw": 2.6630712716269046e-5
    },
    "model.decoder.layers.0.self_attn.v_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 0,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.005695343017578125, -0.01363372802734375, -0.0168609619140625,
            -0.01480865478515625, 0.01305389404296875
        ],
        "importance": 0.31500608313221756,
        "fisher": 0.0023585464921779932,
        "snip": 0.0002587620134969863,
        "gradient_count": 30,
        "importance_raw": 0.0013086542528374897
    },
    "model.decoder.layers.0.self_attn.q_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 0,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.01146697998046875, -0.003467559814453125, -0.0240325927734375,
            -0.010467529296875, 0.00044083595275878906
        ],
        "importance": 0.00575177094745368,
        "fisher": 1.8072477564601287e-5,
        "snip": 3.9084860812484594e-5,
        "gradient_count": 30,
        "importance_raw": 2.857866918854294e-5
    },
    "model.decoder.layers.0.self_attn.out_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 0,
            "attention_type": "output_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.0080108642578125, 0.00390625, 0.0208282470703125,
            0.0169830322265625, -0.002166748046875
        ],
        "importance": 0.204804660616694,
        "fisher": 0.0014988629710084448,
        "snip": 0.00020614685563487002,
        "gradient_count": 30,
        "importance_raw": 0.0008525049133216574
    },
    "model.decoder.layers.0.encoder_attn.k_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 0,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.01074981689453125, 0.0135955810546875, -0.01107025146484375,
            0.0091705322265625, 0.0258026123046875
        ],
        "importance": 0.00488777280943576,
        "fisher": 3.162285421846415e-5,
        "snip": 1.8381905344237264e-5,
        "gradient_count": 30,
        "importance_raw": 2.5002379781350705e-5
    },
    "model.decoder.layers.0.encoder_attn.v_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 0,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.01189422607421875, 0.0031890869140625, -0.00489044189453125,
            -0.00754547119140625, -0.00567626953125
        ],
        "importance": 0.04435479191390308,
        "fisher": 0.00033075339136606394,
        "snip": 4.597772591902564e-5,
        "gradient_count": 30,
        "importance_raw": 0.00018836555864254478
    },
    "model.decoder.layers.0.encoder_attn.q_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 0,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.009765625, 0.025360107421875, -0.00702667236328125,
            0.0005307197570800781, -0.0071258544921875
        ],
        "importance": 0.0017429231047910536,
        "fisher": 8.54233450506096e-6,
        "snip": 1.542789514132892e-5,
        "gradient_count": 30,
        "importance_raw": 1.198511482319494e-5
    },
    "model.decoder.layers.0.encoder_attn.out_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 0,
            "attention_type": "output_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.0019550323486328125, -0.0015878677368164062,
            -0.006999969482421875, -0.00015985965728759766, -0.0080108642578125
        ],
        "importance": 0.02692184370039294,
        "fisher": 0.00017086721121207423,
        "snip": 6.154584498290206e-5,
        "gradient_count": 30,
        "importance_raw": 0.00011620652809748815
    },
    "model.decoder.layers.0.fc1.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "feed_forward",
            "layer_num": 0,
            "attention_type": "none"
        },
        "shape": [3072, 768],
        "size": 2359296,
        "param_sample": [
            0.0011138916015625, -0.0006346702575683594, 0.006053924560546875,
            -0.0026111602783203125, 0.0034389495849609375
        ],
        "importance": 0.02424157734036892,
        "fisher": 0.0001708286421489902,
        "snip": 3.9395921339746566e-5,
        "gradient_count": 30,
        "importance_raw": 0.00010511228174436837
    },
    "model.decoder.layers.0.fc2.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "feed_forward",
            "layer_num": 0,
            "attention_type": "none"
        },
        "shape": [768, 3072],
        "size": 2359296,
        "param_sample": [
            0.005168914794921875, -0.0034160614013671875, 0.005550384521484375,
            -0.004138946533203125, -0.01120758056640625
        ],
        "importance": 0.06175040145262443,
        "fisher": 0.00047132780940349525,
        "snip": 4.941226203906505e-5,
        "gradient_count": 30,
        "importance_raw": 0.00026037003572128016
    },
    "model.decoder.layers.1.self_attn.k_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 1,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.0113677978515625, -0.004085540771484375, -4.559755325317383e-5,
            -0.01458740234375, -0.00574493408203125
        ],
        "importance": 0.0077750198784424344,
        "fisher": 5.265207488870753e-5,
        "snip": 2.1254660047513123e-5,
        "gradient_count": 30,
        "importance_raw": 3.6953367468110326e-5
    },
    "model.decoder.layers.1.self_attn.v_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 1,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.0085296630859375, -0.00839996337890625, -9.465217590332031e-5,
            -0.00644683837890625, 0.0013151168823242188
        ],
        "importance": 0.03907727490378708,
        "fisher": 0.0002864800375391496,
        "snip": 4.656133702762115e-5,
        "gradient_count": 30,
        "importance_raw": 0.0001665206872833854
    },
    "model.decoder.layers.1.self_attn.q_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 1,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.01397705078125, 0.011199951171875, 6.461143493652344e-5,
            0.01538848876953125, -0.01062774658203125
        ],
        "importance": 0.0040175061163771385,
        "fisher": 2.8088217823096785e-5,
        "snip": 1.4712068908314299e-5,
        "gradient_count": 30,
        "importance_raw": 2.1400143365705543e-5
    },
    "model.decoder.layers.1.self_attn.out_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 1,
            "attention_type": "output_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.0006055831909179688, 0.0025615692138671875, -0.0082244873046875,
            0.01654052734375, 0.008270263671875
        ],
        "importance": 0.044243994281696036,
        "fisher": 0.0003104373458578872,
        "snip": 6.53765370467833e-5,
        "gradient_count": 30,
        "importance_raw": 0.00018790694145233525
    },
    "model.decoder.layers.1.encoder_attn.k_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 1,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.01171875, -0.0159149169921875, -0.0478515625,
            -0.00276947021484375, 0.03558349609375
        ],
        "importance": 0.0022211966936574847,
        "fisher": 1.3244266926903948e-5,
        "snip": 1.4685334144814988e-5,
        "gradient_count": 30,
        "importance_raw": 1.3964800535859469e-5
    },
    "model.decoder.layers.1.encoder_attn.v_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 1,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.01110076904296875, -0.01061248779296875, -0.004238128662109375,
            -0.0016489028930664062, 1.615285873413086e-5
        ],
        "importance": 0.026692919347767602,
        "fisher": 0.00019405614257266278,
        "snip": 3.6461771257260506e-5,
        "gradient_count": 30,
        "importance_raw": 0.00011525895691496164
    },
    "model.decoder.layers.1.encoder_attn.q_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 1,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.0211181640625, 0.00688934326171875, 0.0032958984375,
            -2.8014183044433594e-6, -0.0169219970703125
        ],
        "importance": 0.001045681095122148,
        "fisher": 4.2192176351818486e-6,
        "snip": 1.3978918059365241e-5,
        "gradient_count": 30,
        "importance_raw": 9.099067847273544e-6
    },
    "model.decoder.layers.1.encoder_attn.out_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 1,
            "attention_type": "output_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.005992889404296875, -0.0130767822265625, 0.007476806640625,
            -0.007068634033203125, 0.004161834716796875
        ],
        "importance": 0.024861756483577503,
        "fisher": 0.00016342658182111336,
        "snip": 5.19321133348664e-5,
        "gradient_count": 30,
        "importance_raw": 0.00010767934757798988
    },
    "model.decoder.layers.1.fc1.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "feed_forward",
            "layer_num": 1,
            "attention_type": "none"
        },
        "shape": [3072, 768],
        "size": 2359296,
        "param_sample": [
            -0.0027332305908203125, 0.040802001953125, -0.03253173828125,
            0.006443023681640625, -0.0024204254150390625
        ],
        "importance": 0.017670920355359988,
        "fisher": 0.00012095352376491064,
        "snip": 3.487608228169847e-5,
        "gradient_count": 30,
        "importance_raw": 7.791480302330456e-5
    },
    "model.decoder.layers.1.fc2.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "feed_forward",
            "layer_num": 1,
            "attention_type": "none"
        },
        "shape": [768, 3072],
        "size": 2359296,
        "param_sample": [
            -0.0168304443359375, -0.03961181640625, 0.009674072265625,
            0.00978851318359375, 0.004322052001953125
        ],
        "importance": 0.014540712245191958,
        "fisher": 9.908080316260263e-5,
        "snip": 3.083548290305771e-5,
        "gradient_count": 30,
        "importance_raw": 6.495814303283018e-5
    },
    "model.decoder.layers.2.self_attn.k_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 2,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -8.535385131835938e-5, -0.00591278076171875, 1.7762184143066406e-5,
            -0.003330230712890625, 0.003021240234375
        ],
        "importance": 0.18960136171258848,
        "fisher": 0.0015553723783038246,
        "snip": 2.377746222919086e-5,
        "gradient_count": 30,
        "importance_raw": 0.0007895749202665078
    },
    "model.decoder.layers.2.self_attn.v_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 2,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -8.165836334228516e-6, -0.00833892822265625, 3.153085708618164e-5,
            -0.00015676021575927734, -0.00035190582275390625
        ],
        "importance": 0.19348824698454203,
        "fisher": 0.0015764448401265933,
        "snip": 3.488244619802572e-5,
        "gradient_count": 30,
        "importance_raw": 0.0008056636431623095
    },
    "model.decoder.layers.2.self_attn.q_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 2,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            4.553794860839844e-5, 0.0037841796875, 5.882978439331055e-5,
            -0.002262115478515625, -0.008575439453125
        ],
        "importance": 0.08185169892631013,
        "fisher": 0.0006740398549785217,
        "snip": 1.3108114959929177e-5,
        "gradient_count": 30,
        "importance_raw": 0.00034357398496922544
    },
    "model.decoder.layers.2.self_attn.out_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 2,
            "attention_type": "output_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.0004544258117675781, 0.0012769699096679688,
            0.0008296966552734375, -0.004436492919921875, 0.005870819091796875
        ],
        "importance": 0.04665782373092456,
        "fisher": 0.00033821199722297026,
        "snip": 5.758468960266327e-5,
        "gradient_count": 30,
        "importance_raw": 0.00019789834341281677
    },
    "model.decoder.layers.2.encoder_attn.k_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 2,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.002399444580078125, -0.0019083023071289062, -0.1148681640625,
            -0.0115966796875, 0.01369476318359375
        ],
        "importance": 0.006106392479840299,
        "fisher": 4.0322873746845286e-5,
        "snip": 1.9770186766739548e-5,
        "gradient_count": 30,
        "importance_raw": 3.0046530256792417e-5
    },
    "model.decoder.layers.2.encoder_attn.v_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 2,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.0009393692016601562, 0.0017461776733398438, 0.00457000732421875,
            -0.0016336441040039062, 0.004550933837890625
        ],
        "importance": 0.05274654288187958,
        "fisher": 0.0003953170188954876,
        "snip": 5.088491961942054e-5,
        "gradient_count": 30,
        "importance_raw": 0.00022310096925745408
    },
    "model.decoder.layers.2.encoder_attn.q_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 2,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.001605987548828125, -6.562471389770508e-5, -0.02398681640625,
            -0.0295867919921875, 0.00022518634796142578
        ],
        "importance": 0.0022177737426978513,
        "fisher": 1.1532946988760765e-5,
        "snip": 1.6368317301385104e-5,
        "gradient_count": 30,
        "importance_raw": 1.3950632145072935e-5
    },
    "model.decoder.layers.2.encoder_attn.out_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 2,
            "attention_type": "output_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.01366424560546875, -0.0092010498046875, 0.003955841064453125,
            0.02313232421875, 0.01363372802734375
        ],
        "importance": 0.03224609393649888,
        "fisher": 0.00020881019433242423,
        "snip": 6.767948398191947e-5,
        "gradient_count": 30,
        "importance_raw": 0.00013824483915717185
    },
    "model.decoder.layers.2.fc1.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "feed_forward",
            "layer_num": 2,
            "attention_type": "none"
        },
        "shape": [3072, 768],
        "size": 2359296,
        "param_sample": [
            -0.0296783447265625, -0.003810882568359375, 0.006114959716796875,
            0.0018482208251953125, 0.00036716461181640625
        ],
        "importance": 0.047876553388555315,
        "fisher": 0.00037371693021365595,
        "snip": 3.216896808832341e-5,
        "gradient_count": 30,
        "importance_raw": 0.0002029429491509897
    },
    "model.decoder.layers.2.fc2.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "feed_forward",
            "layer_num": 2,
            "attention_type": "none"
        },
        "shape": [768, 3072],
        "size": 2359296,
        "param_sample": [
            -0.012969970703125, -0.005413055419921875, 2.473592758178711e-5,
            -0.004756927490234375, 0.0037097930908203125
        ],
        "importance": 0.011909269963421254,
        "fisher": 8.474330018846862e-5,
        "snip": 2.3388681620417627e-5,
        "gradient_count": 30,
        "importance_raw": 5.4065990904443126e-5
    },
    "model.decoder.layers.3.self_attn.k_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 3,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.01511383056640625, 0.009429931640625, 0.0034999847412109375,
            0.0244140625, -0.018218994140625
        ],
        "importance": 0.0021321970907616497,
        "fisher": 9.23116455548249e-6,
        "snip": 1.796165637036514e-5,
        "gradient_count": 30,
        "importance_raw": 1.3596410462923816e-5
    },
    "model.decoder.layers.3.self_attn.v_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 3,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.0098114013671875, 0.0277252197265625, 0.0011110305786132812,
            -0.0082244873046875, 0.004055023193359375
        ],
        "importance": 0.06362098850820083,
        "fisher": 0.00044373289662568517,
        "snip": 9.249276530075198e-5,
        "gradient_count": 30,
        "importance_raw": 0.0002681128309632186
    },
    "model.decoder.layers.3.self_attn.q_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 3,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.00524139404296875, -0.0189971923828125, -0.00543212890625,
            -0.00681304931640625, 0.034820556640625
        ],
        "importance": 0.0009816873320041709,
        "fisher": 3.927324795919655e-6,
        "snip": 1.374104073571895e-5,
        "gradient_count": 30,
        "importance_raw": 8.834182765819301e-6
    },
    "model.decoder.layers.3.self_attn.out_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 3,
            "attention_type": "output_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.0027408599853515625, 0.00182342529296875, -0.0024623870849609375,
            0.0012102127075195312, 0.00821685791015625
        ],
        "importance": 0.08459316472013124,
        "fisher": 0.0005748568291892298,
        "snip": 0.00013498627085937188,
        "gradient_count": 30,
        "importance_raw": 0.0003549215500243008
    },
    "model.decoder.layers.3.encoder_attn.k_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 3,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.004909515380859375, 0.0005950927734375, 0.04290771484375,
            0.0007519721984863281, 0.00699615478515625
        ],
        "importance": 0.013363724992099868,
        "fisher": 8.494852563671884e-5,
        "snip": 3.522411201023109e-5,
        "gradient_count": 30,
        "importance_raw": 6.0086318823474966e-5
    },
    "model.decoder.layers.3.encoder_attn.v_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 3,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.0015964508056640625, 0.01531982421875, -0.00339508056640625,
            0.0008034706115722656, 0.0033283233642578125
        ],
        "importance": 0.02384667964131076,
        "fisher": 0.0001702576667109194,
        "snip": 3.669774978334317e-5,
        "gradient_count": 30,
        "importance_raw": 0.00010347770824713128
    },
    "model.decoder.layers.3.encoder_attn.q_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 3,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.0070037841796875, -0.004436492919921875, -0.0009746551513671875,
            0.025634765625, -0.005725860595703125
        ],
        "importance": 0.010398276205079268,
        "fisher": 5.52318570347173e-5,
        "snip": 4.039141501076908e-5,
        "gradient_count": 30,
        "importance_raw": 4.781163602274319e-5
    },
    "model.decoder.layers.3.encoder_attn.out_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 3,
            "attention_type": "output_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.01021575927734375, -0.003772735595703125, -0.003139495849609375,
            0.005222320556640625, -0.00876617431640625
        ],
        "importance": 0.015775268919657952,
        "fisher": 9.398885104019427e-5,
        "snip": 4.61476699153233e-5,
        "gradient_count": 30,
        "importance_raw": 7.006826047775878e-5
    },
    "model.decoder.layers.3.fc1.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "feed_forward",
            "layer_num": 3,
            "attention_type": "none"
        },
        "shape": [3072, 768],
        "size": 2359296,
        "param_sample": [
            -0.002593994140625, 0.03155517578125, -0.0008015632629394531,
            -0.0290069580078125, -0.02935791015625
        ],
        "importance": 0.015112662429151007,
        "fisher": 8.467080497212009e-5,
        "snip": 4.998035098348434e-5,
        "gradient_count": 30,
        "importance_raw": 6.732557797780221e-5
    },
    "model.decoder.layers.3.fc2.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "feed_forward",
            "layer_num": 3,
            "attention_type": "none"
        },
        "shape": [768, 3072],
        "size": 2359296,
        "param_sample": [
            -0.03564453125, -0.0013532638549804688, 0.034423828125,
            0.006282806396484375, 0.01303863525390625
        ],
        "importance": 0.01567023475872946,
        "fisher": 8.799101397016784e-5,
        "snip": 5.127598530331549e-5,
        "gradient_count": 30,
        "importance_raw": 6.963349963674166e-5
    },
    "model.decoder.layers.4.self_attn.k_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 4,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.019622802734375, -0.00830841064453125, 0.0032482147216796875,
            0.00928497314453125, -0.085205078125
        ],
        "importance": 0.004231186077949269,
        "fisher": 1.6038638189759998e-5,
        "snip": 2.8530590740653375e-5,
        "gradient_count": 30,
        "importance_raw": 2.2284614465206688e-5
    },
    "model.decoder.layers.4.self_attn.v_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 4,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.0005359649658203125, 0.003688812255859375, -0.0225830078125,
            0.0024547576904296875, -0.01282501220703125
        ],
        "importance": 0.12736262717947514,
        "fisher": 0.0009119482342309008,
        "snip": 0.000151960387059565,
        "gradient_count": 30,
        "importance_raw": 0.0005319543106452329
    },
    "model.decoder.layers.4.self_attn.q_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 4,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.00864410400390625, 0.0252532958984375, -0.0008282661437988281,
            -0.052978515625, -0.0010499954223632812
        ],
        "importance": 0.0030400636425659835,
        "fisher": 1.002251615318528e-5,
        "snip": 2.4686046738982744e-5,
        "gradient_count": 30,
        "importance_raw": 1.7354281446084012e-5
    },
    "model.decoder.layers.4.self_attn.out_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 4,
            "attention_type": "output_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.0081634521484375, 0.005115509033203125, 0.01227569580078125,
            -0.00640106201171875, -0.01227569580078125
        ],
        "importance": 0.07871884837797581,
        "fisher": 0.0005032566676770027,
        "snip": 0.0001579561069471917,
        "gradient_count": 30,
        "importance_raw": 0.00033060638731209716
    },
    "model.decoder.layers.4.encoder_attn.k_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 4,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.00763702392578125, 0.00457763671875, 0.0238494873046875,
            -0.00933837890625, 0.0166778564453125
        ],
        "importance": 0.032377103730181725,
        "fisher": 0.00023026606413623085,
        "snip": 4.7308174240849134e-5,
        "gradient_count": 30,
        "importance_raw": 0.00013878711918854
    },
    "model.decoder.layers.4.encoder_attn.v_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 4,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.00595855712890625, 0.01064300537109375, -0.0007262229919433594,
            -0.006191253662109375, -0.020416259765625
        ],
        "importance": 0.05538981733778888,
        "fisher": 0.000423014323314419,
        "snip": 4.506987170316279e-5,
        "gradient_count": 30,
        "importance_raw": 0.0002340420975087909
    },
    "model.decoder.layers.4.encoder_attn.q_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 4,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.00841522216796875, -0.020416259765625, 0.011993408203125,
            -0.0007128715515136719, 0.012420654296875
        ],
        "importance": 0.02292687469826377,
        "fisher": 0.0001450630098285425,
        "snip": 5.4277833138864175e-5,
        "gradient_count": 30,
        "importance_raw": 9.967042148370334e-5
    },
    "model.decoder.layers.4.encoder_attn.out_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 4,
            "attention_type": "output_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.019622802734375, 0.0128326416015625, -0.01251983642578125,
            -0.00858306884765625, -0.005458831787109375
        ],
        "importance": 0.0314652522910738,
        "fisher": 0.0002120456828076082,
        "snip": 5.7979824850917795e-5,
        "gradient_count": 30,
        "importance_raw": 0.000135012753829263
    },
    "model.decoder.layers.4.fc1.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "feed_forward",
            "layer_num": 4,
            "attention_type": "none"
        },
        "shape": [3072, 768],
        "size": 2359296,
        "param_sample": [
            -0.00579833984375, 0.00298309326171875, -0.0114898681640625,
            0.0125885009765625, 0.01419830322265625
        ],
        "importance": 0.015020627649481496,
        "fisher": 7.433932557129689e-5,
        "snip": 5.9549923632099916e-5,
        "gradient_count": 30,
        "importance_raw": 6.69446246016984e-5
    },
    "model.decoder.layers.4.fc2.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "feed_forward",
            "layer_num": 4,
            "attention_type": "none"
        },
        "shape": [768, 3072],
        "size": 2359296,
        "param_sample": [
            -0.0063323974609375, -0.006855010986328125, 0.00565338134765625,
            0.0011987686157226562, 0.002193450927734375
        ],
        "importance": 0.015384251637616503,
        "fisher": 7.345073669663785e-5,
        "snip": 6.344876116296898e-5,
        "gradient_count": 30,
        "importance_raw": 6.844974892980342e-5
    },
    "model.decoder.layers.5.self_attn.k_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 5,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.01515960693359375, -0.0233306884765625, -0.0587158203125,
            0.0233917236328125, 0.045135498046875
        ],
        "importance": 0.007361773452520446,
        "fisher": 3.105240956150131e-5,
        "snip": 3.943327907715381e-5,
        "gradient_count": 30,
        "importance_raw": 3.524284431932756e-5
    },
    "model.decoder.layers.5.self_attn.v_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 5,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.00379180908203125, 0.0162200927734375, 0.01055145263671875,
            0.007411956787109375, 0.020294189453125
        ],
        "importance": 0.1349353624458001,
        "fisher": 0.0009465171354046712,
        "snip": 0.00018008211385070656,
        "gradient_count": 30,
        "importance_raw": 0.0005632996246276889
    },
    "model.decoder.layers.5.self_attn.q_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 5,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.002079010009765625, -0.01222991943359375, -0.0222015380859375,
            0.026275634765625, 0.0308380126953125
        ],
        "importance": 0.004975943205636314,
        "fisher": 1.6181240357582283e-5,
        "snip": 3.455343479193592e-5,
        "gradient_count": 30,
        "importance_raw": 2.5367337574759104e-5
    },
    "model.decoder.layers.5.self_attn.out_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 5,
            "attention_type": "output_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.00797271728515625, 0.010223388671875, 0.012420654296875,
            -0.0099334716796875, 0.00617218017578125
        ],
        "importance": 0.08276966384282766,
        "fisher": 0.0005215249436635835,
        "snip": 0.00017322236720550185,
        "gradient_count": 30,
        "importance_raw": 0.0003473736554345427
    },
    "model.decoder.layers.5.encoder_attn.k_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 5,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.0002167224884033203, 0.0056610107421875, -0.0014858245849609375,
            -0.0118865966796875, 0.036529541015625
        ],
        "importance": 0.01569931281934527,
        "fisher": 0.00010104717130161589,
        "snip": 3.8460549694718794e-5,
        "gradient_count": 30,
        "importance_raw": 6.975386049816734e-5
    },
    "model.decoder.layers.5.encoder_attn.v_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 5,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.005970001220703125, 0.004459381103515625, 0.01161956787109375,
            0.00705718994140625, 0.004730224609375
        ],
        "importance": 0.02955497711724839,
        "fisher": 0.00021474811364896595,
        "snip": 3.946324680631127e-5,
        "gradient_count": 30,
        "importance_raw": 0.00012710568022763862
    },
    "model.decoder.layers.5.encoder_attn.q_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 5,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.022125244140625, 0.005199432373046875, -0.0002219676971435547,
            -0.017242431640625, 0.01080322265625
        ],
        "importance": 0.01405018638410136,
        "fisher": 7.748333831235262e-5,
        "snip": 4.83721463145533e-5,
        "gradient_count": 30,
        "importance_raw": 6.292774231345296e-5
    },
    "model.decoder.layers.5.encoder_attn.out_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 5,
            "attention_type": "output_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.0102691650390625, -0.00945281982421875, -0.006641387939453125,
            -0.01262664794921875, 0.00888824462890625
        ],
        "importance": 0.018668218260917704,
        "fisher": 0.00011307728879425364,
        "snip": 5.100841359914436e-5,
        "gradient_count": 30,
        "importance_raw": 8.2042851196699e-5
    },
    "model.decoder.layers.5.fc1.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "feed_forward",
            "layer_num": 5,
            "attention_type": "none"
        },
        "shape": [3072, 768],
        "size": 2359296,
        "param_sample": [
            -0.0185089111328125, -0.0013751983642578125, 0.01081085205078125,
            0.00603485107421875, 0.00701904296875
        ],
        "importance": 0.016209736414820902,
        "fisher": 8.045610793487868e-5,
        "snip": 6.327713720869118e-5,
        "gradient_count": 30,
        "importance_raw": 7.186662257178493e-5
    },
    "model.decoder.layers.5.fc2.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "feed_forward",
            "layer_num": 5,
            "attention_type": "none"
        },
        "shape": [768, 3072],
        "size": 2359296,
        "param_sample": [
            -0.01201629638671875, -0.01282501220703125, 0.0092315673828125,
            0.03399658203125, -0.007305145263671875
        ],
        "importance": 0.016795064197084198,
        "fisher": 7.559507309148708e-5,
        "snip": 7.298378792863029e-5,
        "gradient_count": 30,
        "importance_raw": 7.428943051005868e-5
    },
    "model.decoder.layers.6.self_attn.k_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 6,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.01078033447265625, 0.034576416015625, -0.0056610107421875,
            0.01468658447265625, 0.0038928985595703125
        ],
        "importance": 0.010673685603821025,
        "fisher": 4.921074435818203e-5,
        "snip": 4.869249490487467e-5,
        "gradient_count": 30,
        "importance_raw": 4.895161963152835e-5
    },
    "model.decoder.layers.6.self_attn.v_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 6,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.0207672119140625, 0.005184173583984375, -0.0036983489990234375,
            0.00295257568359375, -0.00243377685546875
        ],
        "importance": 0.11359566671160834,
        "fisher": 0.0007697030106404175,
        "snip": 0.00018023630279155137,
        "gradient_count": 30,
        "importance_raw": 0.00047496965671598443
    },
    "model.decoder.layers.6.self_attn.q_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 6,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.0291290283203125, 0.01490020751953125, 0.00405120849609375,
            -0.0006499290466308594, 0.02490234375
        ],
        "importance": 0.006036726409982562,
        "fisher": 2.035806580048908e-5,
        "snip": 3.915826655429555e-5,
        "gradient_count": 30,
        "importance_raw": 2.9758166177392317e-5
    },
    "model.decoder.layers.6.self_attn.out_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 6,
            "attention_type": "output_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.0155792236328125, -0.009185791015625, 0.0131683349609375,
            0.0119476318359375, 0.025146484375
        ],
        "importance": 0.07283743493371846,
        "fisher": 0.00044384764429802697,
        "snip": 0.00016867605178655747,
        "gradient_count": 30,
        "importance_raw": 0.0003062618480422922
    },
    "model.decoder.layers.6.encoder_attn.k_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 6,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.00762939453125, -0.0005717277526855469, 0.006549835205078125,
            -0.01259613037109375, -0.016510009765625
        ],
        "importance": 0.00909420916368858,
        "fisher": 6.11176928941859e-5,
        "snip": 2.3709905084009126e-5,
        "gradient_count": 30,
        "importance_raw": 4.241379898909751e-5
    },
    "model.decoder.layers.6.encoder_attn.v_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 6,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.028472900390625, -0.007144927978515625, -0.0016775131225585938,
            -0.01427459716796875, -0.00872802734375
        ],
        "importance": 0.010208639795763001,
        "fisher": 6.306507687744063e-5,
        "snip": 3.0988296687913436e-5,
        "gradient_count": 30,
        "importance_raw": 4.7026686782677034e-5
    },
    "model.decoder.layers.6.encoder_attn.q_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 6,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.0106658935546875, -0.004573822021484375, -0.0330810546875,
            -0.00017976760864257812, 0.0008754730224609375
        ],
        "importance": 0.0057401731260503745,
        "fisher": 2.9206118385142568e-5,
        "snip": 2.7855207827087723e-5,
        "gradient_count": 30,
        "importance_raw": 2.8530663106115146e-5
    },
    "model.decoder.layers.6.encoder_attn.out_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 6,
            "attention_type": "output_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.0305023193359375, -0.0318603515625, -0.0562744140625,
            -0.007259368896484375, 0.00336456298828125
        ],
        "importance": 0.009528726481592847,
        "fisher": 4.554554861897486e-5,
        "snip": 4.2879186003119686e-5,
        "gradient_count": 30,
        "importance_raw": 4.4212367311047276e-5
    },
    "model.decoder.layers.6.fc1.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "feed_forward",
            "layer_num": 6,
            "attention_type": "none"
        },
        "shape": [3072, 768],
        "size": 2359296,
        "param_sample": [
            -0.0286407470703125, -0.003204345703125, 0.0045166015625,
            -0.01421356201171875, 0.040435791015625
        ],
        "importance": 0.01694218449369035,
        "fisher": 9.07262333688171e-5,
        "snip": 5.90705579573599e-5,
        "gradient_count": 30,
        "importance_raw": 7.48983956630885e-5
    },
    "model.decoder.layers.6.fc2.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "feed_forward",
            "layer_num": 6,
            "attention_type": "none"
        },
        "shape": [768, 3072],
        "size": 2359296,
        "param_sample": [
            0.00852203369140625, -0.01302337646484375, 0.0244140625,
            -0.03167724609375, 0.0299072265625
        ],
        "importance": 0.016627675203649047,
        "fisher": 7.49366821764852e-5,
        "snip": 7.225645482928182e-5,
        "gradient_count": 30,
        "importance_raw": 7.359656850288351e-5
    },
    "model.decoder.layers.7.self_attn.k_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 7,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.01058197021484375, -0.025543212890625, -0.0012912750244140625,
            -0.0164947509765625, -0.0224609375
        ],
        "importance": 0.04377871591258049,
        "fisher": 0.0002835762291700424,
        "snip": 8.838586278822428e-5,
        "gradient_count": 30,
        "importance_raw": 0.00018598104597913334
    },
    "model.decoder.layers.7.self_attn.v_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 7,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.000732421875, 0.00848388671875, 0.001094818115234375,
            -0.01378631591796875, 0.00054168701171875
        ],
        "importance": 0.16928314247030454,
        "fisher": 0.0011827418095587442,
        "snip": 0.0002282043530916174,
        "gradient_count": 30,
        "importance_raw": 0.0007054730813251808
    },
    "model.decoder.layers.7.self_attn.q_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 7,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.007282257080078125, -0.04156494140625, -0.0074615478515625,
            -0.0138397216796875, 0.0130615234375
        ],
        "importance": 0.019634134240777843,
        "fisher": 0.00010134044969163369,
        "snip": 7.074155485800779e-5,
        "gradient_count": 30,
        "importance_raw": 8.604100227482074e-5
    },
    "model.decoder.layers.7.self_attn.out_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 7,
            "attention_type": "output_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.030609130859375, 0.0119171142578125, 0.026580810546875,
            -0.01058197021484375, -0.0056304931640625
        ],
        "importance": 0.10828706823567233,
        "fisher": 0.0006904717782163061,
        "snip": 0.00021552048565354198,
        "gradient_count": 30,
        "importance_raw": 0.00045299613193492403
    },
    "model.decoder.layers.7.encoder_attn.k_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 7,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.0016222000122070312, 0.0158538818359375, 0.003406524658203125,
            0.006877899169921875, 0.004192352294921875
        ],
        "importance": 0.052133508396680225,
        "fisher": 0.0003785458290318881,
        "snip": 6.258112462091958e-5,
        "gradient_count": 30,
        "importance_raw": 0.00022056347682640384
    },
    "model.decoder.layers.7.encoder_attn.v_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 7,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.0010557174682617188, -0.0128631591796875, 0.002696990966796875,
            0.0027790069580078125, -0.016571044921875
        ],
        "importance": 0.019482444219183413,
        "fisher": 0.00013888037683500442,
        "snip": 3.1945867097723145e-5,
        "gradient_count": 30,
        "importance_raw": 8.541312196636378e-5
    },
    "model.decoder.layers.7.encoder_attn.q_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 7,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.024566650390625, -0.027435302734375, 0.0016040802001953125,
            -0.0277099609375, 0.00652313232421875
        ],
        "importance": 0.0458524699046769,
        "fisher": 0.00030277967016445473,
        "snip": 8.634992276104944e-5,
        "gradient_count": 30,
        "importance_raw": 0.00019456479646275208
    },
    "model.decoder.layers.7.encoder_attn.out_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 7,
            "attention_type": "output_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.0017309188842773438, 0.01995849609375, 0.0182647705078125,
            0.01123809814453125, 0.0012722015380859375
        ],
        "importance": 0.009405631014804855,
        "fisher": 4.936732478502866e-5,
        "snip": 3.8038368256820834e-5,
        "gradient_count": 30,
        "importance_raw": 4.370284652092475e-5
    },
    "model.decoder.layers.7.fc1.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "feed_forward",
            "layer_num": 7,
            "attention_type": "none"
        },
        "shape": [3072, 768],
        "size": 2359296,
        "param_sample": [
            0.0240020751953125, 0.0128021240234375, 0.0030269622802734375,
            0.02447509765625, -0.00921630859375
        ],
        "importance": 0.01848017136367467,
        "fisher": 0.0001072607519745361,
        "snip": 5.5268210659657294e-5,
        "gradient_count": 30,
        "importance_raw": 8.126448131709669e-5
    },
    "model.decoder.layers.7.fc2.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "feed_forward",
            "layer_num": 7,
            "attention_type": "none"
        },
        "shape": [768, 3072],
        "size": 2359296,
        "param_sample": [
            -0.0181732177734375, -0.00502777099609375, -0.01186370849609375,
            0.03497314453125, 0.005435943603515625
        ],
        "importance": 0.012962507216965213,
        "fisher": 5.58942686135803e-5,
        "snip": 6.0956901506870054e-5,
        "gradient_count": 30,
        "importance_raw": 5.842558506022518e-5
    },
    "model.decoder.layers.8.self_attn.k_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 8,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.0347900390625, 0.0019292831420898438, 0.00896453857421875,
            -0.01003265380859375, -0.0242462158203125
        ],
        "importance": 0.011754335644579192,
        "fisher": 6.180849492617805e-5,
        "snip": 4.504086846282007e-5,
        "gradient_count": 30,
        "importance_raw": 5.342468169449906e-5
    },
    "model.decoder.layers.8.self_attn.v_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 8,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.01158905029296875, -0.0030918121337890625,
            -0.00016820430755615234, -0.021148681640625, 0.006198883056640625
        ],
        "importance": 0.07494373843582816,
        "fisher": 0.00047267567618594815,
        "snip": 0.0001572849808629447,
        "gradient_count": 30,
        "importance_raw": 0.00031498032852444644
    },
    "model.decoder.layers.8.self_attn.q_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 8,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.00765228271484375, 0.0126190185546875, 0.00870513916015625,
            -0.01262664794921875, 0.0136871337890625
        ],
        "importance": 0.006505268921214183,
        "fisher": 2.6318565536106082e-5,
        "snip": 3.707657985311622e-5,
        "gradient_count": 30,
        "importance_raw": 3.1697572694611154e-5
    },
    "model.decoder.layers.8.self_attn.out_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 8,
            "attention_type": "output_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.003520965576171875, -0.01276397705078125, -6.270408630371094e-5,
            0.01322174072265625, 0.01110076904296875
        ],
        "importance": 0.044871092212495675,
        "fisher": 0.00024757124944396004,
        "snip": 0.00013343404207262212,
        "gradient_count": 30,
        "importance_raw": 0.00019050264575829108
    },
    "model.decoder.layers.8.encoder_attn.k_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 8,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.00775146484375, 0.0262908935546875, 0.039703369140625,
            -0.01520538330078125, 0.0382080078125
        ],
        "importance": 0.0025617085442623763,
        "fisher": 1.1940763283746491e-5,
        "snip": 1.8807753410025422e-5,
        "gradient_count": 30,
        "importance_raw": 1.5374258346885956e-5
    },
    "model.decoder.layers.8.encoder_attn.v_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 8,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.00421142578125, -0.0030460357666015625, 0.0031833648681640625,
            0.005313873291015625, -0.0222320556640625
        ],
        "importance": 0.005037922557594841,
        "fisher": 3.204967342753662e-5,
        "snip": 1.9198095651518086e-5,
        "gradient_count": 30,
        "importance_raw": 2.5623884539527353e-5
    },
    "model.decoder.layers.8.encoder_attn.q_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 8,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.01198577880859375, 0.033721923828125, 0.001132965087890625,
            -0.00019931793212890625, 0.017578125
        ],
        "importance": 0.004281315599915343,
        "fisher": 1.7964705042080215e-5,
        "snip": 2.701951940859241e-5,
        "gradient_count": 30,
        "importance_raw": 2.249211222533631e-5
    },
    "model.decoder.layers.8.encoder_attn.out_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 8,
            "attention_type": "output_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.006420135498046875, -0.0092010498046875, -0.0245819091796875,
            -0.00168609619140625, -0.003387451171875
        ],
        "importance": 0.0036258116698562296,
        "fisher": 1.3240476558470012e-5,
        "snip": 2.6317181194220515e-5,
        "gradient_count": 30,
        "importance_raw": 1.9778828876345265e-5
    },
    "model.decoder.layers.8.fc1.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "feed_forward",
            "layer_num": 8,
            "attention_type": "none"
        },
        "shape": [3072, 768],
        "size": 2359296,
        "param_sample": [
            0.0221099853515625, -0.0085601806640625, 0.004535675048828125,
            -0.00019049644470214844, -0.00916290283203125
        ],
        "importance": 0.010066079702709818,
        "fisher": 4.980487853269248e-5,
        "snip": 4.306831621458211e-5,
        "gradient_count": 30,
        "importance_raw": 4.643659737363729e-5
    },
    "model.decoder.layers.8.fc2.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "feed_forward",
            "layer_num": 8,
            "attention_type": "none"
        },
        "shape": [768, 3072],
        "size": 2359296,
        "param_sample": [
            -0.005130767822265625, -0.0034732818603515625,
            0.0023174285888671875, -0.0023937225341796875, -0.01499176025390625
        ],
        "importance": 0.009505051040843497,
        "fisher": 4.014373074217777e-5,
        "snip": 4.808500755946928e-5,
        "gradient_count": 30,
        "importance_raw": 4.411436915082352e-5
    },
    "model.decoder.layers.9.self_attn.k_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 9,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.0003790855407714844, -0.0004062652587890625,
            0.0001575946807861328, -0.038055419921875, -0.00433349609375
        ],
        "importance": 0.012486399181973078,
        "fisher": 6.680144021326365e-5,
        "snip": 4.6108285944986466e-5,
        "gradient_count": 30,
        "importance_raw": 5.645486307912506e-5
    },
    "model.decoder.layers.9.self_attn.v_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 9,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.027191162109375, 0.007320404052734375, -0.0026912689208984375,
            -0.039276123046875, -0.0181884765625
        ],
        "importance": 0.04708417524251691,
        "fisher": 0.00027323768711842906,
        "snip": 0.0001260885360049239,
        "gradient_count": 30,
        "importance_raw": 0.0001996631115616765
    },
    "model.decoder.layers.9.self_attn.q_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 9,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.0026683807373046875, 0.018798828125, 0.007526397705078125,
            -0.03985595703125, 0.0023479461669921875
        ],
        "importance": 0.007820316294209019,
        "fisher": 3.2140625323033115e-5,
        "snip": 4.2141094430310964e-5,
        "gradient_count": 30,
        "importance_raw": 3.7140859876672036e-5
    },
    "model.decoder.layers.9.self_attn.out_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 9,
            "attention_type": "output_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.0008425712585449219, -0.036285400390625, 0.00606536865234375,
            0.0082855224609375, -0.027252197265625
        ],
        "importance": 0.02833096201566105,
        "fisher": 0.00014083679816394578,
        "snip": 0.00010324159544931415,
        "gradient_count": 30,
        "importance_raw": 0.00012203919680662997
    },
    "model.decoder.layers.9.encoder_attn.k_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 9,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.01558685302734375, 0.0138092041015625, 0.0052032470703125,
            0.010650634765625, -0.01373291015625
        ],
        "importance": 0.003019843344840614,
        "fisher": 1.3493605933945219e-5,
        "snip": 2.1047563920243798e-5,
        "gradient_count": 30,
        "importance_raw": 1.7270584927094508e-5
    },
    "model.decoder.layers.9.encoder_attn.v_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 9,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.001605987548828125, 0.0030460357666015625, 0.005657196044921875,
            -0.036712646484375, -0.00966644287109375
        ],
        "importance": 0.0018222341487538864,
        "fisher": 9.191877279590698e-6,
        "snip": 1.5434926111386935e-5,
        "gradient_count": 30,
        "importance_raw": 1.2313401695488816e-5
    },
    "model.decoder.layers.9.encoder_attn.q_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 9,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.01971435546875, 0.0182037353515625, -0.002689361572265625,
            -0.018951416015625, 0.01079559326171875
        ],
        "importance": 0.005440156908912182,
        "fisher": 2.3711231415290966e-5,
        "snip": 3.0866420881163016e-5,
        "gradient_count": 30,
        "importance_raw": 2.728882614822699e-5
    },
    "model.decoder.layers.9.encoder_attn.out_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 9,
            "attention_type": "output_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.0040130615234375, -0.0238189697265625, -0.002864837646484375,
            0.0183563232421875, 0.0056304931640625
        ],
        "importance": 0.002645764261347662,
        "fisher": 7.72978188858057e-6,
        "snip": 2.3714587162733853e-5,
        "gradient_count": 30,
        "importance_raw": 1.572218452565721e-5
    },
    "model.decoder.layers.9.fc1.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "feed_forward",
            "layer_num": 9,
            "attention_type": "none"
        },
        "shape": [3072, 768],
        "size": 2359296,
        "param_sample": [
            -0.0205078125, 0.0254974365234375, -0.012451171875,
            0.0025787353515625, 0.027313232421875
        ],
        "importance": 0.005448389066810909,
        "fisher": 2.4384326843573943e-5,
        "snip": 3.0261475088385245e-5,
        "gradient_count": 30,
        "importance_raw": 2.7322900965979594e-5
    },
    "model.decoder.layers.9.fc2.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "feed_forward",
            "layer_num": 9,
            "attention_type": "none"
        },
        "shape": [768, 3072],
        "size": 2359296,
        "param_sample": [
            -0.014190673828125, -0.004085540771484375, 0.002063751220703125,
            -0.00992584228515625, 0.01290130615234375
        ],
        "importance": 0.00580643307271211,
        "fisher": 2.682767596221917e-5,
        "snip": 3.0782180935299645e-5,
        "gradient_count": 30,
        "importance_raw": 2.8804928448759407e-5
    },
    "model.decoder.layers.10.self_attn.k_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 10,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.0106048583984375, 0.0007123947143554688, 0.024505615234375,
            0.0168609619140625, -0.033538818359375
        ],
        "importance": 0.006509823532754949,
        "fisher": 3.0335244385544987e-5,
        "snip": 3.309760619837713e-5,
        "gradient_count": 30,
        "importance_raw": 3.171642529196106e-5
    },
    "model.decoder.layers.10.self_attn.v_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 10,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.01654052734375, -0.0027828216552734375, -0.0005712509155273438,
            0.0103302001953125, 0.0121002197265625
        ],
        "importance": 0.02250092941504695,
        "fisher": 0.00010963489912683145,
        "snip": 8.617977049046507e-5,
        "gradient_count": 30,
        "importance_raw": 9.790733480864825e-5
    },
    "model.decoder.layers.10.self_attn.q_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 10,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.048828125, 0.0079498291015625, 0.005878448486328125,
            0.0243072509765625, -0.0236968994140625
        ],
        "importance": 0.0037413596706519867,
        "fisher": 1.2824058831029107e-5,
        "snip": 2.7690159064756396e-5,
        "gradient_count": 30,
        "importance_raw": 2.0257108947892753e-5
    },
    "model.decoder.layers.10.self_attn.out_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 10,
            "attention_type": "output_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.017181396484375, -0.03192138671875, 0.01025390625,
            0.005146026611328125, 0.0200042724609375
        ],
        "importance": 0.01690546061065552,
        "fisher": 7.141059929078134e-5,
        "snip": 7.808217463510422e-5,
        "gradient_count": 30,
        "importance_raw": 7.474638696294277e-5
    },
    "model.decoder.layers.10.encoder_attn.k_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 10,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.0179595947265625, 0.00714874267578125, -0.029815673828125,
            -0.0220794677734375, 0.007137298583984375
        ],
        "importance": 0.0013233683819066796,
        "fisher": 5.734021806347301e-6,
        "snip": 1.4762938523441941e-5,
        "gradient_count": 30,
        "importance_raw": 1.0248480164894622e-5
    },
    "model.decoder.layers.10.encoder_attn.v_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 10,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.044097900390625, 0.016387939453125, -0.0028629302978515625,
            -0.037872314453125, 5.739927291870117e-5
        ],
        "importance": 0.0008324721150098639,
        "fisher": 4.245100702367684e-6,
        "snip": 1.2187991796963615e-5,
        "gradient_count": 30,
        "importance_raw": 8.216546249665649e-6
    },
    "model.decoder.layers.10.encoder_attn.q_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 10,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.00754547119140625, 0.0260009765625, -0.098388671875,
            -0.005657196044921875, 0.01399993896484375
        ],
        "importance": 0.002752743687215976,
        "fisher": 1.075542412915335e-5,
        "snip": 2.1574570412970693e-5,
        "gradient_count": 30,
        "importance_raw": 1.6164997271062022e-5
    },
    "model.decoder.layers.10.encoder_attn.out_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 10,
            "attention_type": "output_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.01343536376953125, -0.0169525146484375, 0.006946563720703125,
            -0.004535675048828125, 0.01371002197265625
        ],
        "importance": 0.001557408371929487,
        "fisher": 3.982411961563533e-6,
        "snip": 1.84520403612017e-5,
        "gradient_count": 30,
        "importance_raw": 1.1217226161382617e-5
    },
    "model.decoder.layers.10.fc1.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "feed_forward",
            "layer_num": 10,
            "attention_type": "none"
        },
        "shape": [3072, 768],
        "size": 2359296,
        "param_sample": [
            0.016876220703125, 0.02606201171875, -0.01189422607421875,
            0.0082244873046875, 0.0183563232421875
        ],
        "importance": 0.005172262942025969,
        "fisher": 2.8160938927612734e-5,
        "snip": 2.4198962394924215e-5,
        "gradient_count": 30,
        "importance_raw": 2.6179950661268474e-5
    },
    "model.decoder.layers.10.fc2.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "feed_forward",
            "layer_num": 10,
            "attention_type": "none"
        },
        "shape": [768, 3072],
        "size": 2359296,
        "param_sample": [
            -0.021331787109375, -0.01171112060546875, -0.0224761962890625,
            -0.03216552734375, -0.017425537109375
        ],
        "importance": 0.003588012750856938,
        "fisher": 1.987796637574017e-5,
        "snip": 1.9366774328470152e-5,
        "gradient_count": 30,
        "importance_raw": 1.962237035210516e-5
    },
    "model.decoder.layers.11.self_attn.k_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 11,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.01349639892578125, -0.00537109375, 0.00920867919921875,
            0.00860595703125, -0.00846099853515625
        ],
        "importance": 0.00235024514078781,
        "fisher": 1.0878037301154109e-5,
        "snip": 1.8119886893449195e-5,
        "gradient_count": 30,
        "importance_raw": 1.4498962097301652e-5
    },
    "model.decoder.layers.11.self_attn.v_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 11,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.0075531005859375, -0.01375579833984375, 0.00502777099609375,
            0.0200958251953125, 0.00914764404296875
        ],
        "importance": 0.014549626253214942,
        "fisher": 6.707997799821896e-5,
        "snip": 6.291010237570541e-5,
        "gradient_count": 30,
        "importance_raw": 6.49950401869622e-5
    },
    "model.decoder.layers.11.self_attn.q_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 11,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.004795074462890625, -0.009063720703125, -0.00504302978515625,
            -0.02191162109375, 0.002498626708984375
        ],
        "importance": 0.0012025673613036785,
        "fisher": 4.372296568059634e-6,
        "snip": 1.512461667516618e-5,
        "gradient_count": 30,
        "importance_raw": 9.748456621612907e-6
    },
    "model.decoder.layers.11.self_attn.out_proj.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "self_attention",
            "layer_num": 11,
            "attention_type": "output_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            0.003021240234375, -0.0203094482421875, -0.031585693359375,
            -0.0020961761474609375, 0.01055145263671875
        ],
        "importance": 0.015017695721229761,
        "fisher": 6.331308134879995e-5,
        "snip": 7.05518959875917e-5,
        "gradient_count": 30,
        "importance_raw": 6.693248866819582e-5
    },
    "model.decoder.layers.11.encoder_attn.k_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 11,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.00687408447265625, -0.021148681640625, 0.01479339599609375,
            0.025421142578125, 0.0119171142578125
        ],
        "importance": 0.0013318730908912387,
        "fisher": 7.397254618505637e-6,
        "snip": 1.3170111651561456e-5,
        "gradient_count": 30,
        "importance_raw": 1.0283683135033547e-5
    },
    "model.decoder.layers.11.encoder_attn.v_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 11,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.026092529296875, 0.0024547576904296875, 0.0005908012390136719,
            0.0199127197265625, -0.0132293701171875
        ],
        "importance": 0.0027315587234408283,
        "fisher": 1.5039962287725453e-5,
        "snip": 1.7114653261766458e-5,
        "gradient_count": 30,
        "importance_raw": 1.6077307774745955e-5
    },
    "model.decoder.layers.11.encoder_attn.q_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 11,
            "attention_type": "qkv_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.017730712890625, 0.0151519775390625, -0.0031757354736328125,
            -0.023101806640625, -0.016510009765625
        ],
        "importance": 0.002542224006753351,
        "fisher": 1.1450248594731723e-5,
        "snip": 1.9136966026659746e-5,
        "gradient_count": 30,
        "importance_raw": 1.5293607310695735e-5
    },
    "model.decoder.layers.11.encoder_attn.out_proj.weight": {
        "category": {
            "component": "encoder",
            "layer_type": "cross_attention",
            "layer_num": 11,
            "attention_type": "output_projection"
        },
        "shape": [768, 768],
        "size": 589824,
        "param_sample": [
            -0.0203399658203125, -0.009307861328125, 0.00852203369140625,
            -0.00870513916015625, 0.0021820068359375
        ],
        "importance": 0.003125636148100211,
        "fisher": 9.954253854023893e-6,
        "snip": 2.5462718076596504e-5,
        "gradient_count": 30,
        "importance_raw": 1.77084859653102e-5
    },
    "model.decoder.layers.11.fc1.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "feed_forward",
            "layer_num": 11,
            "attention_type": "none"
        },
        "shape": [3072, 768],
        "size": 2359296,
        "param_sample": [
            -0.03387451171875, 0.0158233642578125, 0.01372528076171875,
            0.00591278076171875, 0.0214385986328125
        ],
        "importance": 0.02057806721135342,
        "fisher": 0.00014910359289691162,
        "snip": 3.0792728224090146e-5,
        "gradient_count": 30,
        "importance_raw": 8.994816056050089e-5
    },
    "model.decoder.layers.11.fc2.weight": {
        "category": {
            "component": "decoder",
            "layer_type": "feed_forward",
            "layer_num": 11,
            "attention_type": "none"
        },
        "shape": [768, 3072],
        "size": 2359296,
        "param_sample": [
            0.0158843994140625, 0.0204010009765625, 0.002777099609375,
            0.0184173583984375, 0.005138397216796875
        ],
        "importance": 0.012562924444392045,
        "fisher": 7.975795027353646e-5,
        "snip": 3.378528763278155e-5,
        "gradient_count": 30,
        "importance_raw": 5.6771618953159006e-5
    }
}
